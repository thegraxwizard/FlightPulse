{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "296b3a22-c146-4277-a569-6e90855a52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete: 'df_transformed' is ready.\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: SETUP\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, dayofweek\n",
    "\n",
    "spark = SparkSession.builder.appName(\"FlightPulse-ML\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"flights.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_transformed = df.withColumn(\n",
    "    \"flight_date_formatted\", \n",
    "    to_date(col(\"FLIGHT_DATE\"), \"dd-MM-yyyy\")\n",
    ").withColumn(\n",
    "    \"day_of_week\",\n",
    "    dayofweek(col(\"flight_date_formatted\"))\n",
    ")\n",
    "print(\"Setup Complete: 'df_transformed' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b00982e4-2be2-4d3c-82cf-ea98fa7b3fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete: 'ml_ready_data' is ready for training.\n",
      "+-----+-----+------------------------+\n",
      "|HAUL |label|features                |\n",
      "+-----+-----+------------------------+\n",
      "|LONG |1    |[2.0,8.0,49.0,178.0,3.0]|\n",
      "|LONG |1    |[0.0,8.0,49.0,178.0,3.0]|\n",
      "|SHORT|0    |[2.0,0.0,17.0,163.0,2.0]|\n",
      "|SHORT|0    |[1.0,0.0,8.0,172.0,1.0] |\n",
      "|SHORT|0    |[1.0,0.0,13.0,167.0,2.0]|\n",
      "+-----+-----+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 (FINAL CORRECTED Version): FEATURE ENGINEERING\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "df_with_label = df_transformed.withColumn(\"label\", (col(\"HAUL\") == \"LONG\").cast(\"integer\"))\n",
    "\n",
    "# We are removing ALL the perfect predictors to create a real challenge.\n",
    "categorical_cols = [\"TIME_OF_DAY\"] \n",
    "numerical_cols = [\"FIRST_CLASS_SEATS\", \"BUSINESS_CLASS_SEATS\", \"ECONOMY_SEATS\", \"day_of_week\"]\n",
    "\n",
    "# --- THIS IS THE CORRECTED PART ---\n",
    "# The indexers stage remains the same\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_index\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "\n",
    "# This line is now corrected to properly loop through the categorical_cols list.\n",
    "assembler_inputs = [f\"{c}_index\" for c in categorical_cols] + numerical_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "ml_ready_data = pipeline.fit(df_with_label).transform(df_with_label)\n",
    "\n",
    "print(\"Feature Engineering Complete: 'ml_ready_data' is ready for training.\")\n",
    "ml_ready_data.select(\"HAUL\", \"label\", \"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "befa9c0a-d1ce-4283-85ae-72fab01648d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split into training and testing sets.\n",
      "Training set count: 8079\n",
      "Testing set count: 1921\n",
      "\n",
      "Training the Logistic Regression model...\n",
      "Model training complete!\n",
      "\n",
      "Making predictions on the testing data...\n",
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|    0|       0.0|           [1.0,0.0]|\n",
      "|    1|       1.0|[5.88202104098990...|\n",
      "|    0|       0.0|[0.99999999994785...|\n",
      "|    0|       0.0|[0.99999995503898...|\n",
      "|    1|       1.0|[5.88202104098990...|\n",
      "|    1|       1.0|[6.93720081605577...|\n",
      "|    1|       1.0|[6.93720081605577...|\n",
      "|    0|       0.0|           [1.0,0.0]|\n",
      "|    0|       0.0|           [1.0,0.0]|\n",
      "|    1|       1.0|[4.89317936678709...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Logistic Regression model from Spark's ML library\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# --- 1. Split the Data ---\n",
    "# It's a standard and crucial practice in machine learning to split your data into two sets:\n",
    "# - A 'training' set (which we use to teach the model)\n",
    "# - A 'testing' set (which we use to evaluate how well the model learned, on data it has never seen before)\n",
    "# We'll use an 80/20 split.\n",
    "(training_data, testing_data) = ml_ready_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Data has been split into training and testing sets.\")\n",
    "print(f\"Training set count: {training_data.count()}\")\n",
    "print(f\"Testing set count: {testing_data.count()}\")\n",
    "\n",
    "\n",
    "# --- 2. Create and Train the Model ---\n",
    "# Create an instance of the Logistic Regression algorithm\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Train the model by fitting it to our training data\n",
    "print(\"\\nTraining the Logistic Regression model...\")\n",
    "lr_model = lr.fit(training_data)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "\n",
    "# --- 3. Make Predictions ---\n",
    "# Now, let's see how our trained model performs on the 'testing' data it has never seen\n",
    "print(\"\\nMaking predictions on the testing data...\")\n",
    "predictions = lr_model.transform(testing_data)\n",
    "\n",
    "# Show a few key columns from the predictions DataFrame\n",
    "# - 'label' is the actual, true answer.\n",
    "# - 'prediction' is what our model guessed.\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e64161c-3384-4845-9bab-c886209f8d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0| 1163|\n",
      "|    1|       1.0|  758|\n",
      "+-----+----------+-----+\n",
      "\n",
      "\n",
      "--- Logistic Regression Model Performance ---\n",
      "Total Predictions: 1921\n",
      "Correct Predictions: 1921\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# --- 1. A Deeper Look: The Confusion Matrix ---\n",
    "# A confusion matrix is a table that gives us a more detailed breakdown of our model's performance.\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = predictions.groupBy(\"label\", \"prediction\").count()\n",
    "confusion_matrix.show()\n",
    "\n",
    "\n",
    "# --- 2. Calculate Accuracy Manually ---\n",
    "# We can calculate accuracy from the confusion matrix.\n",
    "# It's (Correct Predictions) / (Total Predictions)\n",
    "\n",
    "# Correct predictions are where label == prediction\n",
    "correct_predictions = predictions.filter(\"label == prediction\").count()\n",
    "\n",
    "# Total predictions is just the total number of rows in our testing set\n",
    "total_predictions = predictions.count()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(\"\\n--- Logistic Regression Model Performance ---\")\n",
    "print(f\"Total Predictions: {total_predictions}\")\n",
    "print(f\"Correct Predictions: {correct_predictions}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e715772-f314-4a88-bcb1-2f1454677c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
